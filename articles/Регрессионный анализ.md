**Регрессионный анализ** — метод моделирования измеряемых данных и исследования их свойств. Данные состоят из пар значений **зависимой переменной** (переменной отклика) и **независимой переменной** (объясняющей переменной). [Регрессионная модель](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C "Регрессионная модель") есть функция независимой переменной и параметров с добавленной [случайной переменной](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D0%BF%D0%B5%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D0%B0%D1%8F&action=edit "Случайная переменная"). Параметры модели настраиваются таким образом, что модель наилучшим образом приближает данные. Критерием качества приближения (целевой функцией) обычно является [среднеквадратичная ошибка](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B5%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%B8%D1%87%D0%BD%D0%B0%D1%8F_%D0%BE%D1%88%D0%B8%D0%B1%D0%BA%D0%B0&action=edit "Среднеквадратичная ошибка"): сумма квадратов разности значений модели и зависимой переменной для всех значений независимой переменной в качестве аргумента. Регрессионный анализ — раздел [математической статистики](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D0%BA%D0%B0 "Математическая статистика")и [машинного обучения](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%88%D0%B8%D0%BD%D0%BD%D0%BE%D0%B5_%D0%BE%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5 "Машинное обучение"). Предполагается, что зависимая переменная есть сумма значений некоторой модели и [случайной величины](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D0%BB%D1%83%D1%87%D0%B0%D0%B9%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0 "Случайная величина"). Относительно характера распределения этой величины делаются предположения, называемые гипотезой порождения данных. Для подтверждения или опровержения этой гипотезы выполняются [статистические тесты](http://www.machinelearning.ru/wiki/index.php?title=%D0%A1%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D0%B9_%D1%82%D0%B5%D1%81%D1%82 "Статистический тест"), называемые [анализом остатков](http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%BE%D1%81%D1%82%D0%B0%D1%82%D0%BA%D0%BE%D0%B2&action=edit "Анализ остатков"). При этом предполагается, что независимая переменная не содержит ошибок. Регрессионный анализ используется для [прогноза](http://www.machinelearning.ru/wiki/index.php?title=%D0%9F%D1%80%D0%BE%D0%B3%D0%BD%D0%BE%D0%B7 "Прогноз"), [анализа временных рядов](http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7_%D0%B2%D1%80%D0%B5%D0%BC%D0%B5%D0%BD%D0%BD%D1%8B%D1%85_%D1%80%D1%8F%D0%B4%D0%BE%D0%B2&action=edit "Анализ временных рядов"), [тестирования гипотез](http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D1%81%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5_%D0%B3%D0%B8%D0%BF%D0%BE%D1%82%D0%B5%D0%B7&action=edit "Тестирование гипотез")и выявления скрытых взаимосвязей в данных.

## Определение регрессионного анализа

[![Выборка может быть не функцией, а отношением. Например, данные для построения регрессии могут быть такими: . В такой выборке одному значению переменной  соответствует несколько значений переменной .](/images/aa45aec38bdf4f329d2fd5662da6565b.gif)](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5:Regression_Analysis_Regression.gif "Выборка может быть не функцией, а отношением. Например, данные для построения регрессии могут быть такими: . В такой выборке одному значению переменной  соответствует несколько значений переменной .")

Выборка может быть не функцией, а отношением. Например, данные для построения регрессии могут быть такими: ![](/images/472f2dd0832a0b89d64a63219690d951). В такой выборке одному значению переменной ![x](/images/48981423e0ea0c2528e76c4e72886832) соответствует несколько значений переменной ![y](/images/b04f085ca1dae087889ac549ba5b18d4).

Регрессия — зависимость [математического ожидания](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B0%D1%82%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BE%D0%B6%D0%B8%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5 "Математическое ожидание") (например, среднего значения) случайной величины от одной или нескольких других случайных величин (свободных переменных), то есть ![](/images/2fccd6425802e7758dc288ab55957b2a). Регрессионным анализом называется поиск такой функции ![f](/images/bb6fcc940de74efa74ba31c0f7109e14), которая описывает эту зависимость. Регрессия может быть представлена в виде суммы неслучайной и случайной составляющих.

![](/images/0b144cb28dfcd3e23348cf58a5d290bc)

где ![f](/images/bb6fcc940de74efa74ba31c0f7109e14) — функция регрессионной зависимости, а ![\nu](/images/381c05a7bfc4664d346ee72462bf3018) — аддитивная случайная величина с нулевым матожиданием. Предположение о характере распределения этой величины называется [гипотезой порождения данных](http://www.machinelearning.ru/wiki/index.php?title=%D0%93%D0%B8%D0%BF%D0%BE%D1%82%D0%B5%D0%B7%D0%B0_%D0%BF%D0%BE%D1%80%D0%BE%D0%B6%D0%B4%D0%B5%D0%BD%D0%B8%D1%8F_%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85&action=edit "Гипотеза порождения данных"). Обычно предполагается, что величина ![\nu](/images/381c05a7bfc4664d346ee72462bf3018)имеет [гауссово распределение](http://www.machinelearning.ru/wiki/index.php?title=%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%BE%D0%B2%D0%BE_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5&action=edit "Гауссово распределение")с нулевым средним и дисперсией ![\sigma^2_\nu](/images/f83f5664b9b455d50fa5b191846c6a0a).

Задача нахождения регрессионной модели нескольких свободных переменных ставится следующим образом. Задана [выборка](http://www.machinelearning.ru/wiki/index.php?title=%D0%92%D1%8B%D0%B1%D0%BE%D1%80%D0%BA%D0%B0 "Выборка") — множество ![\{\mathbf{x}_1,...,\mathbf{x}_N|\mathbf{x}\in\mathbb{R}^M\}](/images/456d3b5c28f283aad721354016b15000) значений свободных переменных и множество ![\{y_1,...,y_N| y\in\mathbb{R}\}](/images/45e708f17c753ef91c5b14a3631e4236)соответствующих им значений зависимой переменной. Эти множества обозначаются как ![D](/images/d5688c712eaec9b623dc53df4499ec62), множество исходных данных ![](/images/fb541c2f0c7c592d76ddfc7abe6a1a6b). Задана [регрессионная модель](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C "Регрессионная модель") — параметрическое семейство функций ![f(\mathbf{w},\mathbf{x})](/images/0e23fde03695e6773a40aa56f5119893))зависящая от параметров ![\mathbf{w}\in\mathbb{R}](/images/1d80a40241fbe55698636c465f5990a2)и свободных переменных ![\mathbf{x}](/images/e04296f5007a692927fdc84ddded9709). Требуется найти наиболее вероятные параметры ![\bar{\mathbf{w}}](/images/d33e984c213fb5aecd29d3ed907096c8):

![](/images/25585dec05d1be6c146cbe1ce528cf35)

Функция вероятности![p](/images/b5824c12fe4952e8fff2d0078ffcb4b5) зависит от гипотезы порождения данных и задается [Байесовским выводом](http://www.machinelearning.ru/wiki/index.php?title=%D0%91%D0%B0%D0%B9%D0%B5%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%B8%D0%B9_%D0%B2%D1%8B%D0%B2%D0%BE%D0%B4&action=edit "Байесовский вывод") или [методом наибольшего правдоподобия](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%B1%D0%BE%D0%BB%D1%8C%D1%88%D0%B5%D0%B3%D0%BE_%D0%BF%D1%80%D0%B0%D0%B2%D0%B4%D0%BE%D0%BF%D0%BE%D0%B4%D0%BE%D0%B1%D0%B8%D1%8F "Метод наибольшего правдоподобия").

## Линейная регрессия

_Основная статья_: _**[Многомерная линейная регрессия](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%BD%D0%BE%D0%B3%D0%BE%D0%BC%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F "Многомерная линейная регрессия")**_

Линейная регрессия предполагает, что функция ![f](/images/bb6fcc940de74efa74ba31c0f7109e14)зависит от параметров ![\mathbf{w}](http://www.machinelearning.ru/mimetex/?\mathbf{w})линейно. При этом линейная зависимость от свободной переменной ![\mathbf{x}](/images/e04296f5007a692927fdc84ddded9709)необязательна,

![](/images/e6012eac013a95ebb57823166a53fdc9)

В случае, когда функция ![g\equiv\text{id}](/images/9f9866764f5acfada9ebacef775cd517)линейная регрессия имеет вид

![ y=\sum_{j=1}^N w_jx_j+\nu=\langle\mathbf{w},\mathbf{x}\rangle +\nu, ](/images/21b03f4814e777fc77d64378adca0f2c)

здесь ![x_j](/images/9f5b0b1468f77ba01f82c3c91ba412a3) — компоненты вектора ![\mathbf{x}](/images/e04296f5007a692927fdc84ddded9709).

Значения параметров в случае линейной регрессии находят с помощью [метода наименьших квадратов](http://www.machinelearning.ru/wiki/index.php?title=%D0%9C%D0%B5%D1%82%D0%BE%D0%B4_%D0%BD%D0%B0%D0%B8%D0%BC%D0%B5%D0%BD%D1%8C%D1%88%D0%B8%D1%85_%D0%BA%D0%B2%D0%B0%D0%B4%D1%80%D0%B0%D1%82%D0%BE%D0%B2 "Метод наименьших квадратов"). Использование этого метода обосновано предположением о [гауссовском распределении](http://www.machinelearning.ru/wiki/index.php?title=%D0%93%D0%B0%D1%83%D1%81%D1%81%D0%BE%D0%B2%D1%81%D0%BA%D0%BE%D0%B5_%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5&action=edit "Гауссовское распределение") случайной переменной.

Разности ![y_i-f(\mathbf{x}_i)](/images/5d28fcd98221479ca547c25c5d18e695)) между фактическими значениями зависимой переменной и восстановленными называются **регрессионными остатками** (residuals). В литературе используются также синонимы: _невязки_ и _ошибки_. Одной из важных оценок критерия качества полученной зависимости является сумма квадратов остатков:

![](/images/6ec156b69566da568fdfa1d08df3cd8b)

Здесь ![SSE](http://www.machinelearning.ru/mimetex/?SSE) — Sum of Squared Errors.

Дисперсия остатков вычисляется по формуле

![\bar{\sigma}^2_\nu=\frac{SSE}{N-2}=MSE.](/images/c3a881e901cbab2886374aa4c3d46415)

Здесь ![MSE](/images/4c50d87cd80f72eca361ef86c455caf8) — Mean Square Error, среднеквадратичная ошибка.

![](/images/e9b832e1878fb4e98542e8e1ab332193.png)

![](/images/7d917fa24fb523c64a5e67634ef7f1ed.png)

На графиках представлены выборки, обозначенные синими точками, и регрессионные зависимости, обозначенные сплошными линиями. По оси абсцисс отложена свободная переменная, а по оси ординат — зависимая. Все три зависимости линейны относительно параметров.

## Нелинейная регрессия

_Основная статья_: _**[Нелинейная регрессия](http://www.machinelearning.ru/wiki/index.php?title=%D0%9D%D0%B5%D0%BB%D0%B8%D0%BD%D0%B5%D0%B9%D0%BD%D0%B0%D1%8F_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D1%8F "Нелинейная регрессия")**_

Нелинейные регрессионные модели — [модели](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C "Регрессионная модель") вида

![](/images/6effc1caab46ec06b9b5e88595f241a7)

которые не могут быть представлены в виде скалярного произведения

![](/images/2f70ed690654fe2bd5639f728a3e888b.png)

где ![\mathbf{w}=[w_1,\ldots, w_n]](http://www.machinelearning.ru/mimetex/?\mathbf{w}=[w_1,\ldots,%20w_n]) — параметры регрессионной модели, ![\mathbf{x}](/images/e04296f5007a692927fdc84ddded9709) — свободная переменная из пространства ![\mathbb{R}^n](/images/5cb311caad5f79e234e92c56f53e3231),![y](/images/8c6a2bb5b0161fe90b6d41f1afe57a80) — зависимая переменная,![\nu](/images/381c05a7bfc4664d346ee72462bf3018) — случайная величина и ![\mathbf{g}=[g_1,\ldots, g_n]](http://www.machinelearning.ru/mimetex/?\mathbf{g}=[g_1,\ldots,%20g_n]) — функция из некоторого заданного множества.

Значения параметров в случае нелинейной регрессии находят с помощью одного из методов градиентного спуска, например [алгоритма Левенберга-Марквардта](http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9B%D0%B5%D0%B2%D0%B5%D0%BD%D0%B1%D0%B5%D1%80%D0%B3%D0%B0-%D0%9C%D0%B0%D1%80%D0%BA%D0%B2%D0%B0%D1%80%D0%B4%D1%82%D0%B0 "Алгоритм Левенберга-Марквардта").

## О терминах

Термин "регрессия" был введён Фрэнсисом Гальтоном в конце 19-го века. Гальтон обнаружил, что дети родителей с высоким или низким ростом обычно не наследуют выдающийся рост и назвал этот феномен "регрессия к посредственности". Сначала этот термин использовался исключительно в биологическом смысле. После работ Карла Пирсона этот термин стали использовать и в статистике.

[![Аппроксимация функций: непрерывная функция  приближает непрерывную или дискретную функцию ](/images/60e02a705e5f353f68b96a1befc2562e.gif)](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5:Regression_Analysis_Approximation.gif "Аппроксимация функций: непрерывная функция  приближает непрерывную или дискретную функцию ")

Аппроксимация функций: непрерывная функция ![f](/images/bb6fcc940de74efa74ba31c0f7109e14)приближает непрерывную или дискретную функцию ![u](/images/2163668fe25618eaed49674617a2da9b)

В статистической литературе различают регрессию с участием одной свободной переменной и с несколькими свободными переменными —_одномерную_ и _многомерную_ регрессию. Предполагается, что мы используем несколько свободных переменных, то есть, свободная переменная — вектор![\mathbf{x}\in\R^N](/images/57f8e8e8d2d36eb0e8793603dea1dfe5). В частных случаях, когда свободная переменная является скаляром, она будет обозначаться ![x](/images/48981423e0ea0c2528e76c4e72886832). Различают_линейную_ и _нелинейную_ регрессию. Если регрессионную модель не является линейной комбинацией функций от параметров, то говорят о нелинейной регрессии. При этом модель может быть произвольной суперпозицией функций ![g](http://www.machinelearning.ru/mimetex/?g) из некоторого набора. Нелинейными моделями являются, экспоненциальные, тригонометрические и другие (например, радиальные базисные функции или персептрон Розенблатта), полагающие зависимость между параметрами и зависимой переменной нелинейной.

Различают_параметрическую_ и _непараметрическую_ регрессию. Строгую границу между этими двумя типами регрессий провести сложно. Сейчас не существует общепринятого критерия отличия одного типа моделей от другого. Например, считается, что линейные модели являются параметрическими, а модели, включающие усреднение зависимой переменной по пространству свободной переменной —непараметрическими. Пример параметрической регресионной модели: линейный предиктор, многослойный персептрон. Примеры смешанной регрессионной модели: функции радиального базиса. Непараметрическая модель — скользящее усреднение в окне некоторой ширины. В целом, непараметрическая регрессия отличается от параметрической тем, что зависимая переменная зависит не от одного значения свободной переменной, а от некоторой заданной окрестности этого значения.

[![Интерполяция: функция  задана значениями узловых точек](/images/ff2c0309926bea9db2e6695ee00ba079.gif)](http://www.machinelearning.ru/wiki/index.php?title=%D0%98%D0%B7%D0%BE%D0%B1%D1%80%D0%B0%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5:Regression_Analysis_Interpolation.gif "Интерполяция: функция  задана значениями узловых точек")

Интерполяция: функция ![f](/images/bb6fcc940de74efa74ba31c0f7109e14) задана значениями узловых точек

Есть различие между терминами: "приближение функций", "аппроксимация", "интерполяция", и "регрессия". Оно заключается в следующем.

_Приближение функций._ Дана функция ![u](/images/2163668fe25618eaed49674617a2da9b)дискретного или непрерывного аргумента. Требуется найти функцию ![f](/images/bb6fcc940de74efa74ba31c0f7109e14)из некоторого параметрическую семейства, например, среди алгебраических полиномов заданной степени. Параметры функции  ![f](/images/bb6fcc940de74efa74ba31c0f7109e14)должны доставлять минимум некоторому функционалу, например,

![](/images/d46d8d76bae2c51bd84c0dd2a1803e8f)

Термин _аппроксимация_ — синоним термина "приближение функций". Чаще используется тогда, когда речь идет о заданной функции, как о функции дискретного аргумента. Здесь также требуется отыскать такую функцию ![f](/images/bb6fcc940de74efa74ba31c0f7109e14), которая проходит наиболее близко ко всем точкам заданной функции. При этом вводится понятие _невязки_ — расстояния между точками непрерывной функции ![f](/images/bb6fcc940de74efa74ba31c0f7109e14)и соответствующими точками функции ![u](/images/2163668fe25618eaed49674617a2da9b)дискретного аргумента.

_Интерполяция_ функций — частный случай задачи приближения, когда требуется, чтобы в определенных точках, называемых _узлами интерполяции_ совпадали значения функции ![u](/images/9e51fb322fd25fce6f9facc5ac7d0fa9)и приближающей ее функции ![f](/images/bb6fcc940de74efa74ba31c0f7109e14). В более общем случае накладываются ограничения на значения некоторых производных ![f](/images/bb6fcc940de74efa74ba31c0f7109e14) производных. То есть, дана функция ![u](/images/2163668fe25618eaed49674617a2da9b) дискретного аргумента. Требуется отыскать такую функцию ![f](/images/bb6fcc940de74efa74ba31c0f7109e14), которая проходит через все точки ![u](/images/2163668fe25618eaed49674617a2da9b). При этом метрика обычно не используется, однако часто вводится понятие "гладкости" искомой функции.

Регрессия и классификация тесно связаны друг с другом. Термин _[алгоритм](http://www.machinelearning.ru/wiki/index.php?title=%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC "Алгоритм")_ в классификации мог бы стать синонимом термина _[модель](http://www.machinelearning.ru/wiki/index.php?title=%D0%A0%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D0%B0%D1%8F_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D1%8C "Регрессионная модель")_ в регрессии, если бы алгоритм не оперировал с дискретным множеством ответов-классов, а модель — с непрерывно-определенной свободной переменной.

**********
[регрессионный анализ](/tags/%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%BE%D0%BD%D0%BD%D1%8B%D0%B9%20%D0%B0%D0%BD%D0%B0%D0%BB%D0%B8%D0%B7.md)
